\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsthm}
\usepackage[margin=2cm]{geometry}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\ud}{\mathrm{d}}
\newcommand{\ue}{\mathrm{e}}
\newcommand{\ui}{\mathrm{i}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%opening
\title{Notes}
\date{\today}
\author{William McLean}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Generalised Crank--Nicolson scheme}
We consider a (stiff) system of fractional ODEs,
\[
\bs{M}\partial_t^\alpha\bs{u}+\bs{A}\bs{u}=\bs{f}(t)
    \quad\text{for $0\le t\le T$,}\quad\text{with $\bs{u}(0)=\bs{u}_0$,}
\]
typically obtained via spatial discretisation of a subdiffusion equation.
For suitable time levels
\[
0=t_0<t_1<t_2<\cdots<t_N=T,
\]
we seek a continuous, piecewise-linear approximation
\[
\bs{u}(t)\approx\bs{U}(t)=\tau_n^{-1}[(t_n-t)\bs{U}^{n-1}+(t-t_{n-1})\bs{U}^n]
\quad\text{for $t\in I_n$,}
\]
where $I_n=(t_{n-1},t_n)$ denotes the $n$th subinterval.  To determine $\bs{U}$,
we require that
\begin{equation}\label{eq: gen CN}
\int_{I_n}\bigl(\bs{M}\partial_t^\alpha\bs{U}+\bs{A}\bs{U}\bigr)\,\ud t
    =\int_{I_n}\bs{f}(t)\,\ud t\quad\text{for $1\le n\le N$,}
\end{equation}
with $\bs{U}^0=\bs{u}_0$.

Observe that
\[
\int_{I_n}\bs{A}\bs{U}\,\ud t=\tau_n\bs{A}\bs{U}^{n-1/2}\quad\text{where}\quad
\bs{U}^{n-1/2}=\frac{1}{\tau_n}\int_{I_n}\bs{U}\,\ud t
    =\frac{1}{2}(\bs{U}^n+\bs{U}^{n-1}),
\]
and define likewise
\[
\bs{F}^{n-1/2}=\frac{1}{\tau_n}\int_{I_n}\bs{f}(t)\,\ud t.
\]
In this way,
\[
\int_{I_n}\bs{M}\partial_t^\alpha\bs{U}\,\ud t+\tau_n\bs{A}\bs{U}^{n-1/2}
    =\tau_n\bs{F}^{n-1/2},
\]
and it remains to consider
\[
\int_{I_n}\bs{M}\partial_t^\alpha\bs{U}\,\ud t
    =\int_{I_n}\bs{M}\mathcal{I}^{1-\alpha}\bs{U}'\,\ud t,
\]
where the fractional integral operator of order~$\beta>0$ is defined as usual by
\[
(\mathcal{I}^\beta v)(t)=\int_0^t\omega_\beta(t-s)v(s)\,\ud s
\quad\text{where}\quad\omega_\beta(t)=\frac{t^{\beta-1}}{\Gamma(\beta)}.
\]
Let us put
\[
\Delta\bs{U}^n=\bs{U}^n-\bs{U}^{n-1},
\]
so that $\bs{U}'(t)=\tau_n^{-1}\Delta\bs{U}^n$ for $t\in I_n$. Thus,
\[
(\mathcal{I}^{1-\alpha}\bs{U}')(t)=\sum_{j=1}^{n-1}\int_{I_j}
    \omega_{1-\alpha}(t-s)\tau_j^{-1}\Delta\bs{U}^j\,\ud s
    +\int_{t_{n-1}}^t\omega_{1-\alpha}(t-s)\tau_n^{-1}\Delta\bs{U}^n\,\ud s,
\]
so, defining
\[
\omega^\alpha_{nn}=\frac{1}{\tau_n}\int_{I_n}\int_{t_{n-1}}^t
    \omega_{1-\alpha}(t-s)\,\ud s\,\ud t>0
\]
and
\[
\omega^\alpha_{nj}=\frac{1}{\tau_j}\int_{I_n}\int_{I_j}
    \omega_{1-\alpha}(t-s)\,\ud s\,\ud t>0,
\]
we have
\[
\int_{I_n}\mathcal{I}^{1-\alpha}\bs{U}'\,\ud t
    =\omega^\alpha_{nn}\Delta\bs{U}^n
    +\sum_{j=1}^{n-1}\omega^\alpha_{nj}\Delta\bs{U}^j.
\]

The preceding calculations show that \eqref{eq: gen CN} holds iff
\[
\sum_{j=1}^n\omega_{nj}^\alpha\bs{M}\Delta\bs{U}^j
    +\tau_n\bs{A}\bs{U}^{n-1/2}=\tau_n\bs{F}^{n-1/2},
\]
and by writing $\bs{U}^{n-1/2}=\bs{U}^{n-1}+\tfrac12\Delta\bs{U}^n$, we find
that
\begin{equation}\label{eq: gen CN linear system}
(\omega_{nn}^\alpha\bs{M}+\tfrac12\tau_n\bs{A})\Delta\bs{U}^n
    =\tau_n\bs{F}^{n-1/2}-\tau_n\bs{A}\bs{U}^{n-1}
    -\sum_{j=1}^{n-1}\omega_{nj}^\alpha\bs{M}\Delta\bs{U}^j.
\end{equation}

Since $\omega_\beta=\omega_{\beta+1}'$,
\[
\int_{I_j}\omega_{1-\alpha}(t-s)\,\ud s
    =\omega_{2-\alpha}(t-t_{j-1})-\omega_{2-\alpha}(t-t_j)
\]
and
\[
\int_{t_{n-1}}^t\omega_{1-\alpha}(t-s)\,\ud s=\omega_{2-\alpha}(t-t_{n-1}),
\]
implying that
\[
\omega^\alpha_{nn}=\frac{\omega_{3-\alpha}(\tau_n)}{\tau_n}
    =\frac{\tau_n^{1-\alpha}}{\Gamma(3-\alpha)}
\]
and
\[
\omega^\alpha_{nj}=\tau_j^{-1}\bigl[
\omega_{3-\alpha}(t_n-t_{j-1})-\omega_{3-\alpha}(t_{n-1}-t_{j-1})
-\omega_{3-\alpha}(t_n-t_j)-\omega_{3-\alpha}(t_{n-1}-t_j)\bigr].
\]
If $\alpha\to1$ then $\omega^\alpha_{nn}\to1$ and
$\omega^\alpha_{nj}\to0$ for $1\le j\le n-1$, and so the
scheme~\eqref{eq: gen CN linear system} becomes
\[
(\bs{M}+\tfrac12\tau_n\bs{A})\Delta\bs{U}^n=\tau_n\bs{F}^{n-1/2}
    -\tau_n\bs{A}\bs{U}^{n-1}.
\]
Equivalently, since $\Delta\bs{U}^n=\bs{U}^n-\bs{U}^{n-1}$,
\[
(\bs{M}+\tfrac12\tau_n\bs{A})\bs{U}^n=\tau_n\bs{F}^{n-1/2}
    +(\bs{M}-\tfrac12\tau_n\bs{A})\bs{U}^{n-1},
\]
so we may view \eqref{eq: gen CN} as a generalisation of the classical
Crank--Nicolson scheme.

For $\alpha\in(0,1)$,
\begin{align*}
\sum_{j=1}^n\omega^\alpha_{nj}\Delta\bs{U}^j
    &=\sum_{j=1}^n\omega^\alpha_{nj}(\bs{U}^j-\bs{U}^{j-1})
    =\sum_{j=1}^n\omega^\alpha_{nj}\bs{U}^j
    -\sum_{j=0}^{n-1}\omega^\alpha_{n,j+1}\bs{U}^j\\
    &=\omega^\alpha_{nn}\bs{U}^n
    -\sum_{j=1}^{n-1}(\omega^\alpha_{n,j+1}-\omega^\alpha_{nj})\bs{U}^j
    -\omega^\alpha_{n1}\bs{U}^0,
\end{align*}
so the scheme may also be written as
\[
(\omega^\alpha_{nn}\bs{M}+\tfrac12\tau_n\bs{A})\bs{U}^n
=\tau_n\bs{F}^{n-1/2}-\tfrac12\tau_n\bs{A}\bs{U}^{n-1}
    +\bs{M}\biggl(\omega_{n1}^\alpha\bs{U}^0
    +\sum_{j=1}^{n-1}(\omega^\alpha_{n,j+1}-\omega^\alpha_{n,j})\bs{U}^j\biggr).
\]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computing the weights}

In the special case of a uniform mesh~$t_n=n\tau$,
\[
\omega^\alpha_{nn}=\frac{\tau^{1-\alpha}}{\Gamma(3-\alpha)}
\]
is independent of~$n$, and for $1\le j\le n-1$,
\[
\omega^\alpha_{nj}=\frac{\tau^{1-\alpha}}{\Gamma(3-\alpha)}\bigl[
    (n-j+1)^{2-\alpha}-2(n-j)^{2-\alpha}+(n-j-1)^{2-\alpha}\bigr]
\]
depends only on the difference~$n-j$.  In the general case, we let
\[
D_{nj}=t_{n-1/2}-t_{j-1/2}\quad\text{and}\quad
\delta_{nj}^\pm=\frac{\tau_n\pm\tau_j}{2D_{nj}},
\]
so that
\begin{align*}
t_n-t_{j-1}&=D_{nj}(1+\delta_{nj}^+),&
t_{n-1}-t_{j-1}&=D_{nj}(1-\delta_{nj}^-),\\
t_n-t_j&=D_{nj}(1+\delta_{nj}^-),&
t_{n-1}-t_j&=D_{nj}(1-\delta_{nj}^+),
\end{align*}
to obtain
\[
\omega^\alpha_{nj}=\frac{\omega_{3-\alpha}(D_{nj})}{\tau_j}\bigl[
 (1+\delta_{nj}^+)^{2-\alpha}-(1-\delta_{nj}^-)^{2-\alpha}
-(1+\delta_{nj}^-)^{2-\alpha}+(1-\delta_{nj}^+)^{2-\alpha}\bigr].
\]

If $\delta_{nj}^\pm$ is small, then direct evaluation will lead to loss of
precision.  We therefore consider the Taylor expansion
\[
(1+\delta)^{2-\alpha}=1+\sum_{m=1}^\infty a_m\delta^m
\quad\text{for $|\delta|<1$,}\quad
\quad\text{where}\quad
a_m=\frac{2-\alpha}{1}\,\frac{1-\alpha}{2}\cdots\frac{3-\alpha-m}{m},
\]
and note that
\[
(1+\delta)^{2-\alpha}+(1-\delta)^{2-\alpha}
    =2+\sum_{m=1}^\infty C_m\delta^{2m},
\quad\text{where}\quad C_m=2a_{2m},
\]
so
\begin{equation}\label{eq: omega series}
\omega^\alpha_{nj}=\frac{\omega_{3-\alpha}(D_{nj})}{\tau_j}\sum_{m=1}^\infty
    C_m\bigl[(\delta_{nj}^+)^{2m}-(\delta_{nj}^-)^{2m}\bigr].
\end{equation}
Furthermore,
\[
\sum_{m=1}^\infty C_m\bigl[(\delta_{nj}^+)^{2m}-(\delta_{nj}^-)^{2m}\bigr]
    =\sum_{m=1}^\infty C_m
    \bigl[(\delta_{nj}^+)^m+|\delta_{nj}^-|^m\bigr]
    \bigl[(\delta_{nj}^+)^m-|\delta_{nj}^-|^m\bigr],
\]
and we have
\[
(\delta_{nj}^+)^m-|\delta_{nj}^-|^m=(\delta_{nj}^+-|\delta_{nj}^-|)
    \sum_{k=1}^m(\delta_{nj}^+)^{m-k}|\delta_{nj}^-|^{k-1}.
\]
Put
\[
b=\frac{\omega_{3-\alpha}(D_{nj})}{\tau_j}\bigl(
    \delta_{nj}^+-|\delta_{nj}^-|\bigr)
    =\frac{D_{nj}^{1-\alpha}}{\Gamma(3-\alpha)}\times\begin{cases}
1&\text{if $\tau_n\ge\tau_j$,}\\
\tau_n/\tau_j&\text{if $\tau_n<\tau_j$,}
\end{cases}
\]
so that
\begin{equation}\label{eq: omega sum}
\omega^\alpha_{nj}=b\sum_{m=1}^\infty C_m
    \bigl[(\delta_{nj}^+)^m+|\delta_{nj}^-|^m\bigr]
    \sum_{k=1}^m(\delta_{nj}^+)^{m-k}|\delta_{nj}^-|^{k-1}.
\end{equation}

When $j=n-1$, since $D_{n,n-1}=\tfrac12(\tau_n+\tau_{n-1})$ we see that
$\delta_{n,n-1}^+=1$ and thus
\[
\omega^\alpha_{n,n-1}=\frac{\omega_{3-\alpha}(D_{n,n-1})}{\tau_{n-1}}
\bigl[
    2^{2-\alpha}-(1-\delta_{n,n-1}^-)^{2-\alpha}
    -(1+\delta_{n,n-1}^-)^{2-\alpha}\bigr]
\]

\begin{lemma}
Assume that $0<\alpha<1$. Then, the coefficients in the
representation~\eqref{eq: omega series} satisfy
\[
1>C_1>C_2>C_3>\cdots>0\quad\text{with}\quad
\lim_{m\to\infty}\frac{C_m}{C_{m-1}}=1.
\]
\end{lemma}
\begin{proof}
Since
\[
C_1=a_2=\frac{2-\alpha}{1}\,\frac{1-\alpha}{2}=(1-\tfrac12\alpha)(1-\alpha)
\]
we see that $0<C_1<1$.  For $m\ge2$,
\[
\frac{C_m}{C_{m-1}}=\frac{a_{2m}}{a_{2m-2}}
    =\frac{4-\alpha-2m}{2m-1}\,\frac{3-\alpha-2m}{2m}
    =\frac{2m+\alpha-4}{2m-1}\,\frac{2m+\alpha-3}{2m},
\]
showing that $0<C_m/C_{m-1}<1$, because $4<2m+\alpha<2m$, and that
$C_m/C_{m-1}\to1$.
\end{proof}

\begin{lemma}
For $0<\delta<1$,
\[
\sum_{m=M+1}^\infty C_m\delta^{2m}\le \frac{C_{M+1}\delta^{2M+2}}{1-\delta^2}.
\]
\end{lemma}
\begin{proof}
Using the formula for the sum of a geometric progression,
\[
\sum_{m=M+1}^\infty C_m\delta^{2m}\le C_{M+1}\sum_{m=M+1}^\infty\delta^{2m}
    =C_{M+1}\delta^{2M+2}\sum_{m=0}^\infty(\delta^2)^m
    =\frac{C_{M+1}\delta^{2M+2}}{1-\delta^2}.
\]
\end{proof}

Retaining just the first term of the outer sum in~\eqref{eq: omega series}, and
assuming that $\delta^-_{nj}$ is negligible compared to $\delta^+_{nj}$, we have
\[
\omega^\alpha_{nj}\approx
\frac{\omega_{3-\alpha}(D_{nj})}{\tau_j}C_1(\delta^+_{nj})^2
    =\frac{C_1}{\Gamma(3-\alpha)}\,
    \frac{(\tau_n+\tau_j)^2}{4\tau_j}\,D_{nj}^{-1-\alpha}
    =\frac{1}{\Gamma(1-\alpha)}\,
    \frac{(\tau_n+\tau_j)^2}{4\tau_j}\,D_{nj}^{-1-\alpha}.
\]
In the special case of a uniform mesh,
\[
\omega^\alpha_{nj}\approx\frac{\tau}{\Gamma(1-\alpha)}\,D_{nj}^{-1-\alpha}.
\]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exponential sum approximation}

Let $\beta>0$, and recall the definition of the Gamma function,
\[
\Gamma(\beta)=\int_0^\infty\ue^{-y}y^\beta\,\frac{\ud y}{y}.
\]
If $t>0$, then the substitution $y=pt$ yields the formula
\[
t^{-\beta}=\frac{1}{\Gamma(\beta)}\int_0^\infty
    \ue^{-pt}p^\beta\,\frac{\ud p}{p}.
\]
Now make the further substitution~\cite{McLean2018} $p=\exp(x-\ue^{-x})$ to
obtain
\[
t^{-\beta}=\frac{1}{\Gamma(\beta)}\int_{-\infty}^\infty
    \exp\bigl(-\varphi(x, t)\bigr)(1+\ue^{-x})\,\ud x,
\]
where
\[
\varphi(x,t)=tp-\beta\log p=t\exp(x-\ue^{-x})-\beta(x-\ue^{-x}).
\]

For a step-size~$\Delta x>0$, let
\[
x_m=m\,\Delta x,\quad
a_m=\exp(x_m-\ue^{-x_m}),\quad
w_m=a_m^\beta(1+\ue^{-x_m})\,\Delta x,
\]
and define the (infinite) quadrature approximation
\[
Q(t;\Delta x)=\frac{1}{\Gamma(\beta)}\sum_{m=-\infty}^\infty
    \exp\bigl(-\varphi(x_m, t)\bigr)(1+\ue^{-x_m})\,\Delta x
=\frac{1}{\Gamma(\beta)}\sum_{m=-\infty}^\infty w_m\ue^{-a_mt}.
\]
Notice that both $w_m$~and $a_m$ are positive, and that $a_m$ does not depend
on~$\beta$. The relative error in the
approximation~$t^{-\beta}\approx Q(t;\Delta x)$ is
\[
\rho(t;\Delta x)=\frac{t^{-\beta}-Q(t;\Delta x)}{t^{-\beta}}
=1-\frac{t^\beta}{\Gamma(\beta)}\sum_{m=-\infty}^\infty w_m\ue^{-a_mt},
\]
and if $0<r<\pi/2$ then~\cite[Theorem~4]{McLean2018}
\begin{equation}\label{eq: relative error}
|\rho(t;\Delta x)|\le C_{\beta,r}\ue^{-2\pi r/\Delta x}
    \quad\text{for $0<t\le 1$.}
\end{equation}

In practice, we have to work with a finite sum
\[
t^{-\beta}\approx
Q_{M,N}(t;\Delta x)=\frac{1}{\Gamma(\beta)}\sum_{m=-M}^Nw_m\ue^{-a_mt}.
\]
Suppose that we want to approximate $t^{-\beta}$ by an exponential sum for
$\delta\le t\le T$.  Since
\[
t^{-\beta}=T^{-\beta}(t/T)^{-\beta}\approx T^{-\beta}Q_{M,N}(t/T; \Delta x),
\]
we choose $M$~and $N$ so that
\[
T^{-\beta}w_m\ue^{-a_m\delta/T}<\mathrm{tol}\quad\text{if $m<-M$ or $m>N$,}
\]
and then plot the relative error $\rho(t/T; \Delta x)$ for~$\delta\le t\le T$
to determine the accuracy of
\[
t^{-\beta}\approx \frac{T^{-\beta}}{\Gamma(\beta)}\sum_{m=-M}^N
    w_m\ue^{-a_mt/T}=\frac{1}{\Gamma(\beta)}\sum_{m=-M}^N W_m\ue^{-A_mt}
\quad\text{where $W_m=\frac{w_m}{T^\beta}$ and $A_m=\frac{a_m}{T}$.}
\]

Assume now that $\beta=1-\alpha$ for $0<\alpha<1$.  The identity
\[
\Gamma(1-\alpha)\Gamma(\alpha)=\frac{\pi}{\sin\pi\alpha}
\]
means that
\begin{equation}\label{eq: omega exponential sum}
\omega_{1-\alpha}(t)=\frac{t^{-\alpha}}{\Gamma(1-\alpha)}
    \approx\frac{\sin\pi\alpha}{\pi}\sum_{m=-M}^NW_m\ue^{-A_mt}.
\end{equation}
We want to use this approximation to speed up the evaluation
of~$\int_{I_n}\partial_t^\alpha U\,dt$.  To that end, write
\[
\int_{I_n}\partial_t^\alpha\bs{U}\,\ud t
    =\int_{I_n}\mathcal{I}^{1-\alpha}U'\,\ud t=J^n_1(t)+J^n_2(t)
\]
where, for an appropriate choice of the index~$r\ge2$ and for $n>r$,
\[
J^n_1(t)=\int_{I_n}\int_{t_{n-r}}^t\omega_{1-\alpha}(t-s)\bs{U}'(s)\,\ud s
\quad\text{and}\quad
J^n_2(t)=\int_{I_n}\int_0^{t_{n-r}}\omega_{1-\alpha}(t-s)\bs{U}'(s)\,\ud s.
\]
By our earlier calculations
\[
J_1^n(t)=\omega^\alpha_{nn}\Delta\bs{U}^n+\sum_{k=n-r+1}^{n-1}
    \omega^\alpha_{nj}\Delta\bs{U}^j
\quad\text{and}\quad
J_2^n(t)=\sum_{j=1}^{n-r}\omega^\alpha_{nj}\Delta\bs{U}^j.
\]

In the double integral defining $J^n_2(t)$, we have $t\ge t_{n-1}$~and
$s\le t_{n-r}$, so $t_{n-1}-t_{n-r}\le t-s\le T$.  Thus, if we put
\[
\delta=\min_{r\le n\le N}(t_{n-1}-t_{n-r})
\]
then, by replacing $t$ with~$t-s$ in~\eqref{eq: omega exponential sum},
\begin{align*}
J_2^n&\approx \hat J_2^n\equiv\frac{\sin\pi\alpha}{\pi}\int_{I_n}
    \int_0^{t_{n-r}}\sum_{m=-M}^N W_m\ue^{-A_m(t-s)}\bs{U}'(s)\,\ud s\,\ud t\\
    &=\frac{\sin\pi\alpha}{\pi}\sum_{m=-M}^N
    \int_{I_n}\ue^{-A_m(t-t_{n-1})}\,\ud t
    \int_0^{t_{n-r}}\ue^{-A_m(t_{n-1}-s)}\bs{U}'(s)\,\ud s.
\end{align*}
Put
\[
S^n_m= c_{n,m}\int_0^{t_{n-r}}\ue^{-A_m(t-t_{n-1})}\bs{U}'(s)\,\ud s
\quad\text{where}\quad
c_{n,m}=\int_{I_n}\ue^{-A_n(t-t_{n-1}}\,\ud t=\frac{1-\ue^{-A_m\tau_n}}{A_m},
\]
so
\[
\hat J^n_2=\frac{\sin\pi\alpha}{\pi}\sum_{m=-M}^N S^n_m,
\]
and note that since $A_m\to0$ as~$m\to-\infty$, to minimise roundoff we should
use the function~$\mathtt{expm1}(x)=\ue^x-1$ to compute
\[
c_{n,m}=\frac{-1}{A_m}\,\mathtt{expm1}(-A_m\tau_n).
\]

Since
\begin{multline*}
\int_0^{t_{n+1-r}}\ue^{-A_m(t_n-s)}\bs{U}'(s)\,\ud s
    =\int_{t_{n-r}}^{t_{n+1-r}}\ue^{-A_m(t_n-s)}
    \frac{\Delta\bs{U}^{n+1-r}}{\tau_{n+1-r}}\,\ud s\\
    +\ue^{-A_m\tau_n}\int_0^{t_{n-r}}\ue^{-A_m(t_{n-1}-s)}\bs{U}'(s)\,\ud s,
\end{multline*}
we may compute the $\hat S^n_m$ recursively, as follows:
\[
\hat S^{n+1}_m=\mu_{m,n}\Delta\bs{U}^{n+1-r}+\nu_{n,m}\hat S^n_m
\quad\text{for $n\ge r$, with $S^r_m=0$,}
\]
where the coefficients are
\[
\mu_{n,m}=c_{n+1,m}\,\frac{\ue^{-A_m(t_n-t_{n-r})}-\ue^{-A_m(t_n-t_{n+1-r})}}%
{A_m\tau_{n+1-r}}
\quad\text{and}\quad
\nu_{n,m}=\frac{c_{n+1,m}}{c_{n,m}}\,e^{-A_m\tau_n}.
\]
To minimse roundoff, we compute
\[
\mu_{n,m}=\frac{c_{n+1,m}}{A_m}\ue^{-A_m(t_n-t_{n-r})}
    \mathtt{expm1}(A_m\tau_{n+1-r}).
\]
Notice that since $e^x-1=x+O(x^2)$ as $x\to0$, if $A_m$ is small then
\[
c_{n,m}\approx\tau_n,\qquad
\mu_{n,m}\approx\tau_{n+1}\tau_{n+1-r},\qquad
\nu_{n,m}\approx\frac{\tau_{n+1}}{\tau_n}.
\]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix\section{Estimate for $C_{\beta,r}$}
We want to obtain an explicit estimate for the constant in the error
bound~\eqref{eq: relative error}.  The key step is to estimate
\[
G_r=\int_{-\infty}^\infty(|f(x+\ui r;t)|+|f(x-\ui r;t)|)\,\ud x
\]
where $f(z;t)=\exp\bigl(-\varphi(z,t)\bigr)(1+\ue^{-z})$.  Let $0<r<\pi/2$ and
$0<t\le 1$, and follow the argument from an earlier
paper~\cite[Lemma~1]{McLean2018}.  We choose $\epsilon>0$ satisfying
\[
0<r+\epsilon<\frac{\pi}{2}
\quad\text{and}\quad
r+\epsilon+\sin r>\frac{\pi}{2},
\]
and define
\[
x^*=\log\frac{\sin r}{\pi/2-r-\epsilon}>0.
\]
Next, set
\[
c=\exp(-\ue^{-x^*}\cos r)\sin\epsilon
    =\exp\bigl(-(\pi/2-r-\epsilon)\cot r\bigr)\sin\epsilon
\]
to arrive at
\[
\int_{x^*}^\infty|f(x\pm\ui r)|\,\ud x\le Ct^{-\beta}
\quad\text{where}\quad
C=\frac{1+e^{-x^*}}{c^\beta}\Gamma(\beta),
\]
and
\[
\int_0^{x^*}|f(x\pm\ui r)|\,\ud x
    \le2x^*\exp(t\ue^{x^*}+\beta x^*),
\]
with
\[
\int_{-\infty}^0|f(x\pm\ui r)|\,\ud x\le C'\ue^t
\quad\text{where}\quad
C'=\int_1^\infty \ue^{-\beta p\cos r}(1+p)\,\frac{\ud p}{p}.
\]
The substitution $y=\beta p\cos r$ gives
\begin{align*}
C'&=\int_{\beta\cos r}^\infty\ue^{-y}\,\frac{dy}{y}
    +\frac{1}{\beta\cos r}\int_{\beta\cos r}^\infty\ue^{-y}\,dy
    \le\int_{\beta\cos r}^1\,\frac{dy}{y}+\int_1^\infty\ue^{-y}\,dy
        +\frac{\ue^{-\beta\cos r}}{\beta\cos r}\\
    &=\log\biggl(\frac{1}{\beta\cos r}\biggr)+\ue^{-1}
        +\frac{\ue^{-\beta\cos r}}{\beta\cos r},
\end{align*}
so, using the assumption that $t\le1$,
\[
G_r\le Ct^{-\beta}+D\quad\text{for}\quad D=2x^*\exp(\ue^{x^*}+\beta x^*)+C'\ue.
\]
It then follows~\cite[Theorem~3]{McLean2018} that
\[
|\rho(t;\Delta x)|
    \le t^\beta\,\frac{G_r\ue^{-2\pi r/\Delta x}}{1-e^{-2\pi r/\Delta x}}
    \le(C+D)\frac{\ue^{-2\pi r/\Delta x}}{1-e^{-2\pi r/\Delta x}}.
\]









%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{0}
\bibitem{McLean2018} William McLean, Exponential sum approximations for
$t^{-\beta}$.  In J. Dick et al. (eds.), \emph{ Contemporary Computational
Mathematics – A Celebration of the 80th Birthday of Ian Sloan}, pp.~911--930.
Springer International Publishing AG, 2018.
\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
